{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING WITH PYTHON COOKBOOK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulating datasets\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, coefficients = make_regression(n_samples = 100,\n",
    "                                                n_features = 3,\n",
    "                                                n_informative = 3,\n",
    "                                                n_targets = 1,\n",
    "                                                noise = 0.0,\n",
    "                                                coef = True,\n",
    "                                                 random_state = 1\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[ 1.29322588 -0.61736206 -0.11044703]\n",
      " [-2.793085    0.36633201  1.93752881]\n",
      " [ 0.80186103 -0.18656977  0.0465673 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Feature Matrix\\n', features[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Vector\n",
      " [-10.37865986  25.5124503   19.67705609]\n"
     ]
    }
   ],
   "source": [
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_classification\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = make_classification(n_samples = 100,\n",
    "                                      n_features = 3,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2, \n",
    "                                       weights = [.25, .75],\n",
    "                                       random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[ 1.06354768 -1.42632219  1.02163151]\n",
      " [ 0.23156977  1.49535261  0.33251578]\n",
      " [ 0.15972951  0.83533515 -0.40869554]]\n",
      "Target Vector\n",
      " [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[ -1.22685609   3.25572052]\n",
      " [ -9.57463218  -4.38310652]\n",
      " [-10.71976941  -4.20558148]]\n",
      "Target Vector\n",
      " [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Make_blobs\n",
    "from sklearn.datasets import make_blobs\n",
    "# Generate feature matrix and target vector\n",
    "features, target = make_blobs(n_samples = 100,\n",
    "n_features = 2,\n",
    "centers = 3,\n",
    "cluster_std = 0.5,\n",
    "shuffle = True,\n",
    "random_state = 1)\n",
    "# View feature matrix and target vector\n",
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize clusters generated by Make_blobs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 0], features[:, 1], c = target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csV\n",
    "# Load dataset\n",
    "#dataframe = pd.read_csv(url)\n",
    "# View first two rows\n",
    "#dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Load excel\\nimport pandas as pd\\n# Create URL\\nurl = 'https://tinyurl.com/simulated_excel'\\n# Load data\\ndataframe = pd.read_excel(url, sheetname=0, header=1)\\n# View the first two rows\\ndataframe.head(2)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Load excel\n",
    "import pandas as pd\n",
    "# Create URL\n",
    "url = 'https://tinyurl.com/simulated_excel'\n",
    "# Load data\n",
    "dataframe = pd.read_excel(url, sheetname=0, header=1)\n",
    "# View the first two rows\n",
    "dataframe.head(2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Load json\\nimport pandas as pd\\n# Create URL\\nurl = 'https://tinyurl.com/simulated_json'\\n# Load data\\ndataframe = pd.read_json(url, orient='columns')\\n# View the first two rows\\ndataframe.head(2)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Load json\n",
    "import pandas as pd\n",
    "# Create URL\n",
    "url = 'https://tinyurl.com/simulated_json'\n",
    "# Load data\n",
    "dataframe = pd.read_json(url, orient='columns')\n",
    "# View the first two rows\n",
    "dataframe.head(2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          NaN       NaN     NaN   \n",
       "1          1.0       0.0     3.0   \n",
       "2          NaN       NaN     NaN   \n",
       "3          2.0       1.0     1.0   \n",
       "4          NaN       NaN     NaN   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                                                NaN     NaN   NaN    NaN   \n",
       "1                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "2                                                NaN     NaN   NaN    NaN   \n",
       "3  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "4                                                NaN     NaN   NaN    NaN   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0    NaN        NaN      NaN   NaN      NaN  \n",
       "1    0.0  A/5 21171   7.2500   NaN        S  \n",
       "2    NaN        NaN      NaN   NaN      NaN  \n",
       "3    0.0   PC 17599  71.2833   C85        C  \n",
       "4    NaN        NaN      NaN   NaN      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. data wrangling\n",
    "import pandas as pd\n",
    "dataframe=pd.read_csv('titanic.csv')\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n",
    "dataframe = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   23   False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Name'] = ['Jacky Jackson', 'Steven Stevenson']\n",
    "dataframe['Age'] = [38, 23]\n",
    "dataframe['Driver'] = [True, False]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Molly Mooney</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   23   False\n",
       "2      Molly Mooney   40    True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_person = pd.Series(['Molly Mooney', 40, True], index=['Name', 'Age', 'Driver'])\n",
    "dataframe.append(new_person, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.2 Describing the data\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.606602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age\n",
       "count   2.000000\n",
       "mean   30.500000\n",
       "std    10.606602\n",
       "min    23.000000\n",
       "25%    26.750000\n",
       "50%    30.500000\n",
       "75%    34.250000\n",
       "max    38.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name      Jacky Jackson\n",
       "Age                  38\n",
       "Driver             True\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.3\n",
    "dataframe.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "3          2.0       1.0     1.0   \n",
       "5          3.0       1.0     3.0   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "3  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "5                             Heikkinen, Miss. Laina  female  26.0    0.0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "3    0.0          PC 17599  71.2833   C85        C  \n",
       "5    0.0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.4\n",
    "# Load library\n",
    "import pandas as pd\n",
    "# Load data\n",
    "dataframe = pd.read_csv('titanic.csv')\n",
    "# Show top two rows where column 'sex' is 'female'\n",
    "dataframe[dataframe['Sex'] == 'female'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1    male\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.5\n",
    "import pandas as pd\n",
    "# Load data\n",
    "df = pd.read_csv('titanic.csv')\n",
    "# Replace values, show two rows\n",
    "df['Sex'].replace(\"female\", \"Woman\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          NaN       NaN     NaN   \n",
       "1          1.0       0.0     3.0   \n",
       "2          NaN       NaN     NaN   \n",
       "3          2.0       1.0     1.0   \n",
       "4          NaN       NaN     NaN   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                                                NaN     NaN   NaN    NaN   \n",
       "1                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "2                                                NaN     NaN   NaN    NaN   \n",
       "3  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "4                                                NaN     NaN   NaN    NaN   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0    NaN        NaN      NaN   NaN      NaN  \n",
       "1    0.0  A/5 21171   7.2500   NaN        S  \n",
       "2    NaN        NaN      NaN   NaN      NaN  \n",
       "3    0.0   PC 17599  71.2833   C85        C  \n",
       "4    NaN        NaN      NaN   NaN      NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Passenger Class  \\\n",
       "0          NaN       NaN              NaN   \n",
       "1          1.0       0.0              3.0   \n",
       "2          NaN       NaN              NaN   \n",
       "3          2.0       1.0              1.0   \n",
       "\n",
       "                                                Name  Gender   Age  SibSp  \\\n",
       "0                                                NaN     NaN   NaN    NaN   \n",
       "1                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "2                                                NaN     NaN   NaN    NaN   \n",
       "3  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0    NaN        NaN      NaN   NaN      NaN  \n",
       "1    0.0  A/5 21171   7.2500   NaN        S  \n",
       "2    NaN        NaN      NaN   NaN      NaN  \n",
       "3    0.0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.6 Renaming columns\n",
    "df.rename(columns = {'Pclass':'Passenger Class', 'Sex':'Gender'}).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum: 80.0\n",
      "Minimum: 0.42\n",
      "Mean: 29.69911764705882\n",
      "Sum: 21205.17\n",
      "Count: 714\n"
     ]
    }
   ],
   "source": [
    "print('Maximum:', df['Age'].max())\n",
    "print('Minimum:', df['Age'].min())\n",
    "print('Mean:', df['Age'].mean())\n",
    "print('Sum:', df['Age'].sum())\n",
    "print('Count:', df['Age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'male', 'female'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    491\n",
       "1.0    216\n",
       "2.0    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass Name  Sex  Age  SibSp  Parch Ticket  Fare  \\\n",
       "0          NaN       NaN     NaN  NaN  NaN  NaN    NaN    NaN    NaN   NaN   \n",
       "2          NaN       NaN     NaN  NaN  NaN  NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "  Cabin Embarked  \n",
       "0   NaN      NaN  \n",
       "2   NaN      NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Age'].isnull()].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                     Name   Sex  SibSp  Parch  \\\n",
       "0          NaN       NaN     NaN                      NaN   NaN    NaN    NaN   \n",
       "1          1.0       0.0     3.0  Braund, Mr. Owen Harris  male    1.0    0.0   \n",
       "\n",
       "      Ticket  Fare Cabin Embarked  \n",
       "0        NaN   NaN   NaN      NaN  \n",
       "1  A/5 21171  7.25   NaN        S  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Age', axis=1).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          NaN       NaN     NaN   \n",
       "1          1.0       0.0     3.0   \n",
       "2          NaN       NaN     NaN   \n",
       "3          2.0       1.0     1.0   \n",
       "4          NaN       NaN     NaN   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                                                NaN     NaN   NaN    NaN   \n",
       "1                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "2                                                NaN     NaN   NaN    NaN   \n",
       "3  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "4                                                NaN     NaN   NaN    NaN   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0    NaN        NaN      NaN   NaN      NaN  \n",
       "1    0.0  A/5 21171   7.2500   NaN        S  \n",
       "2    NaN        NaN      NaN   NaN      NaN  \n",
       "3    0.0   PC 17599  71.2833   C85        C  \n",
       "4    NaN        NaN      NaN   NaN      NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \\\n",
       "0          NaN       NaN     NaN                      NaN   NaN   NaN    NaN   \n",
       "1          1.0       0.0     3.0  Braund, Mr. Owen Harris  male  22.0    1.0   \n",
       "2          NaN       NaN     NaN                      NaN   NaN   NaN    NaN   \n",
       "4          NaN       NaN     NaN                      NaN   NaN   NaN    NaN   \n",
       "6          NaN       NaN     NaN                      NaN   NaN   NaN    NaN   \n",
       "\n",
       "   Parch     Ticket  Fare Cabin Embarked  \n",
       "0    NaN        NaN   NaN   NaN      NaN  \n",
       "1    0.0  A/5 21171  7.25   NaN        S  \n",
       "2    NaN        NaN   NaN   NaN      NaN  \n",
       "4    NaN        NaN   NaN   NaN      NaN  \n",
       "6    NaN        NaN   NaN   NaN      NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Sex'] != 'female'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          NaN       NaN     NaN   \n",
       "1          1.0       0.0     3.0   \n",
       "2          NaN       NaN     NaN   \n",
       "3          2.0       1.0     1.0   \n",
       "4          NaN       NaN     NaN   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                                                NaN     NaN   NaN    NaN   \n",
       "1                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "2                                                NaN     NaN   NaN    NaN   \n",
       "3  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "4                                                NaN     NaN   NaN    NaN   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0    NaN        NaN      NaN   NaN      NaN  \n",
       "1    0.0  A/5 21171   7.2500   NaN        S  \n",
       "2    NaN        NaN      NaN   NaN      NaN  \n",
       "3    0.0   PC 17599  71.2833   C85        C  \n",
       "4    NaN        NaN      NaN   NaN      NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>887.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>888.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>889.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>890.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass  \\\n",
       "0             NaN       NaN     NaN   \n",
       "1             1.0       0.0     3.0   \n",
       "3             2.0       1.0     1.0   \n",
       "5             3.0       1.0     3.0   \n",
       "7             4.0       1.0     1.0   \n",
       "...           ...       ...     ...   \n",
       "1773        887.0       0.0     2.0   \n",
       "1775        888.0       1.0     1.0   \n",
       "1777        889.0       0.0     3.0   \n",
       "1779        890.0       1.0     1.0   \n",
       "1781        891.0       0.0     3.0   \n",
       "\n",
       "                                                   Name     Sex   Age  SibSp  \\\n",
       "0                                                   NaN     NaN   NaN    NaN   \n",
       "1                               Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "3     Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "5                                Heikkinen, Miss. Laina  female  26.0    0.0   \n",
       "7          Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0    1.0   \n",
       "...                                                 ...     ...   ...    ...   \n",
       "1773                              Montvila, Rev. Juozas    male  27.0    0.0   \n",
       "1775                       Graham, Miss. Margaret Edith  female  19.0    0.0   \n",
       "1777           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN    1.0   \n",
       "1779                              Behr, Mr. Karl Howell    male  26.0    0.0   \n",
       "1781                                Dooley, Mr. Patrick    male  32.0    0.0   \n",
       "\n",
       "      Parch            Ticket     Fare Cabin Embarked  \n",
       "0       NaN               NaN      NaN   NaN      NaN  \n",
       "1       0.0         A/5 21171   7.2500   NaN        S  \n",
       "3       0.0          PC 17599  71.2833   C85        C  \n",
       "5       0.0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "7       0.0            113803  53.1000  C123        S  \n",
       "...     ...               ...      ...   ...      ...  \n",
       "1773    0.0            211536  13.0000   NaN        S  \n",
       "1775    0.0            112053  30.0000   B42        S  \n",
       "1777    2.0        W./C. 6607  23.4500   NaN        S  \n",
       "1779    0.0            111369  30.0000  C148        C  \n",
       "1781    0.0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[892 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>424</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>68</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>290</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>136</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
       "Survived                                                                    \n",
       "0.0               549     549   549  549  424    549    549     549   549   \n",
       "1.0               342     342   342  342  290    342    342     342   342   \n",
       "\n",
       "          Cabin  Embarked  \n",
       "Survived                   \n",
       "0.0          68       549  \n",
       "1.0         136       340  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.14 Grouping rows by time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "time_index = pd.date_range('06/06/2017', periods= 100000, freq='30S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sale_Amount'] = np.random.randint(1,10, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>86007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>100836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>101138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-02</th>\n",
       "      <td>100829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>100340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16</th>\n",
       "      <td>10495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11        86007\n",
       "2017-06-18       100836\n",
       "2017-06-25       101138\n",
       "2017-07-02       100829\n",
       "2017-07-09       100340\n",
       "2017-07-16        10495"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:00:00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:00:30</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:01:00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:01:30</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:02:00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Sale_Amount\n",
       "2017-06-06 00:00:00            6\n",
       "2017-06-06 00:00:30            6\n",
       "2017-06-06 00:01:00            5\n",
       "2017-06-06 00:01:30            2\n",
       "2017-06-06 00:02:00            3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.15 looping over a column\n",
    "import pandas as pd\n",
    "df = pd.read_csv('titanic.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chp 4.\n",
    "#rescaling a feature\n",
    "import numpy as np \n",
    "from sklearn import preprocessing \n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Standardizing a feature\n",
    "x = np.array([[-1000.1],\n",
    "                [-200.2],\n",
    "                [500.5],\n",
    "                [600.6],\n",
    "                [9000.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.3 NOrmalizing observations\n",
    "from sklearn.preprocessing import Normalizer\n",
    "features = np.array([[0.5, 0.5],\n",
    "                    [1.1, 3.4],\n",
    "                    [1.5, 20.2],\n",
    "                    [1.63, 34.4],\n",
    "                    [10.9, 3.3]])\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_l2_norm = Normalizer(norm= \"l2\").transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.4 generating polynomial\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "features = np.array([[2, 3],\n",
    "                    [2, 3],\n",
    "                     [2, 3]])\n",
    "polynomial_interaction = PolynomialFeatures(degree= 2, include_bias=False)\n",
    "polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.5 Transforming Features\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "features = np.array([[2,3],\n",
    "                    [2,3],\n",
    "                    [2,3]])\n",
    "def add_ten(x):\n",
    "    return x + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_transformer = FunctionTransformer(add_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can create the same transformation in pandas using apply:\n",
    "df = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.6 Detecting Outliers\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, _ = make_blobs(n_samples = 10, \n",
    "                         n_features = 2,\n",
    "                         centers = 1,\n",
    "                         random_state = 1)\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_detector = EllipticEnvelope(contamination = .1)\n",
    "outlier_detector.fit(features)\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.7 Handling Outliers\n",
    "import pandas as pd\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bathrooms  Square_Feet\n",
       "0  534433        2.0         1500\n",
       "1  392333        3.5         2500\n",
       "2  293222        2.0         1500"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses[houses['Bathrooms']< 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "houses['Outlier'] = np.where(houses['Bathrooms'] < 20, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier\n",
       "0   534433        2.0         1500        0\n",
       "1   392333        3.5         2500        0\n",
       "2   293222        2.0         1500        0\n",
       "3  4322032      116.0        48000        1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses['Log_Of_Square_Feet'] = [np.log(x) for x in houses['Square_Feet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>Log_Of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.778956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier  Log_Of_Square_Feet\n",
       "0   534433        2.0         1500        0            7.313220\n",
       "1   392333        3.5         2500        0            7.824046\n",
       "2   293222        2.0         1500        0            7.313220\n",
       "3  4322032      116.0        48000        1           10.778956"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.8 Discretizating Features\n",
    "from sklearn.preprocessing import Binarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.array([[6],\n",
    "                [12],\n",
    "                [20],\n",
    "                [36],\n",
    "                [65]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(age, bins=[20,30,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.9 Grouping Observations Using Clustering\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, _ = make_blobs(n_samples = 50,\n",
    "                        n_features = 2,\n",
    "                        centers = 3,\n",
    "                        random_state = 1)\n",
    "dataframe = pd.DataFrame(features, columns = ['feature_1', 'feature_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0  -9.877554  -3.336145      2\n",
       "1  -7.287210  -8.353986      0\n",
       "2  -6.943061  -7.023744      0\n",
       "3  -7.440167  -8.791959      0\n",
       "4  -6.641388  -8.075888      0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer = KMeans(3, random_state=0)\n",
    "clusterer.fit(features)\n",
    "dataframe[\"group\"] = clusterer.predict(features)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.10 Deleting Observations with Missing Values\n",
    "features = np.array([[1.1, 11.1],\n",
    "                    [2.2, 22.2],\n",
    "                    [3.3, 33.3],\n",
    "                    [4.4, 44.4],\n",
    "                    [np.nan, 55]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[~np.isnan(features).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also by\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#4.11 Imputing Missing Values\\n#If you have a small amount of data, predict the missing values using k-nearest neighbors(KNN):\\nfrom fancyimpute import KNN\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.datasets import make_blobs\\n\\n#make a simulated feature matrix\\nfeatures, _ = make_blobs(n_samples =1000,\\n                        n_features = 2,\\n                        random_state =1)\\n\\n#standardize\\nscaler = StandardScaler()\\nstandardized_features = scaler.fit_transform(features)\\n\\n# Replace the first feature\\'s first value with a missing value\\ntrue_value = standardized_features[0,0]\\nstandardized_features[0,0] = np.nan\\n\\n# Predict the misssing value in the feature matrix\\nfeatures_knn_imputed = KNN(k=5, verbose=0).complete(standardized_features)\\n\\n#compare true and Imputed values\\nprint(\"True Value\", true_value)\\nprint(\"Imputed Value\", features_knn_imputed[0,0])\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#4.11 Imputing Missing Values\n",
    "#If you have a small amount of data, predict the missing values using k-nearest neighbors(KNN):\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "#make a simulated feature matrix\n",
    "features, _ = make_blobs(n_samples =1000,\n",
    "                        n_features = 2,\n",
    "                        random_state =1)\n",
    "\n",
    "#standardize\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Replace the first feature's first value with a missing value\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan\n",
    "\n",
    "# Predict the misssing value in the feature matrix\n",
    "features_knn_imputed = KNN(k=5, verbose=0).complete(standardized_features)\n",
    "\n",
    "#compare true and Imputed values\n",
    "print(\"True Value\", true_value)\n",
    "print(\"Imputed Value\", features_knn_imputed[0,0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chp 5. Handling Categorical Data\n",
    "#5.1 Encoding Nominal Categorical Features\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "feature = np.array([[\"Texas\"],\n",
    "                    [\"California\"],\n",
    "                    [\"Texas\"],\n",
    "                    [\"Delaware\"],\n",
    "                    [\"Texas\"]])\n",
    "#create one-hot encoder\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "#one-hot encode feature\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view feature classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reverse one-hot encoding\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even use pandas to one-hot encode the feature:\n",
    "import pandas as pd\n",
    "pd.get_dummies(feature[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create multiclass feature\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"),\n",
    "                        (\"California\", \"Alabama\"),\n",
    "                        (\"Texas\", \"Florida\"),\n",
    "                        (\"Delware\", \"Florida\"),\n",
    "                        (\"Texas\", \"Alabama\")]\n",
    "\n",
    "# Create multiclass one-hot encoder\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delware', 'Florida', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.2 Encoding Ordinal Categorical Features (e.g., high, medium, low).\n",
    "df = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
    "\n",
    "#Create mapper\n",
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"High\":3}\n",
    "\n",
    "# Replace feature values with scale:\n",
    "df['Score'].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.3 Encoding Dictionaries of Features\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# Create dictionary\n",
    "data_dict = [{\"Red\": 2, \"Blue\": 4},\n",
    "                {\"Red\": 4, \"Blue\": 3},\n",
    "                {\"Red\": 1, \"Yellow\": 2},\n",
    "                {\"Red\": 2, \"Yellow\": 2}]\n",
    "\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Convert dictionary to feature matrix\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blue', 'Red', 'Yellow']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = dictvectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.4 Imputing Missing Class Values\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create feature matrix with categorical feature\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "                [1, 1.18, 1.33],\n",
    "                [0, 1.22, 1.27],\n",
    "                [1, -0.21, -1.19]])\n",
    "\n",
    "# Create feature matrix with missing values in the categorical feature\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                        [np.nan, -0.67, -0.22]])\n",
    "\n",
    "# Train KNN learner\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "# Predict missing values' class\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
    "\n",
    "# Join column of predicted class with their other features\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "\n",
    "# Join two feature matrices\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.5 Handling Imbalanced Classes\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove first 40 obs\n",
    "features = features[40:,:]\n",
    "target = target[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.where((target == 0), 0, 1)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.9, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create weights\n",
    "weights = {0: .9, 1: 0.1}\n",
    "\n",
    "# Create random forest classifier with weights\n",
    "RandomForestClassifier(class_weight=weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest with balanced class weights\n",
    "RandomForestClassifier(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang. By Aishwarya Henriette',\n",
       " 'Parking And Going. By Karl Gautier',\n",
       " 'Today Is The night. By Jarek Prakash']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chp 6. Handling Text\n",
    "#6.1 Cleaning Text\n",
    "# Create text\n",
    "text_data = [\" Interrobang. By Aishwarya Henriette \",\n",
    "            \"Parking And Going. By Karl Gautier\",\n",
    "            \" Today Is The night. By Jarek Prakash \"]\n",
    "strip_whitespace = [string.strip() for string in text_data]\n",
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang By Aishwarya Henriette',\n",
       " 'Parking And Going By Karl Gautier',\n",
       " 'Today Is The night By Jarek Prakash']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
    "remove_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitilizer(string: str) -> str:\n",
    "    return string.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTERROBANG BY AISHWARYA HENRIETTE',\n",
       " 'PARKING AND GOING BY KARL GAUTIER',\n",
       " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[capitilizer(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replace_letter_with_x(string: str) -> str:\n",
    "    return re.sub(r\"[a-zA-Z]\", \"X\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
       " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
       " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[replace_letter_with_x(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.2 Parsing and Cleaning HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "        <div class='full_name'><span style='font-weight:bold'>\n",
    "        Masego</span> Azra</div>\"\n",
    "        \"\"\"\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "# Find the div with the class \"full_name\", show text\n",
    "soup.find('div', {'class':'full name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Masego Azra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3 Removing Punctuation\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "text_data = ['Hi!!!! I. Love. This. Song....',\n",
    "            '10000% Agree!!!! #LoveIT',\n",
    "            'Right?!?!']\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith(\"P\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[string.translate(punctuation) for string in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Anitya\n",
      "[nltk_data]     Gangurde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.4 Tokenizing Text\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "string = \"The science of today is the technology of tomorrow\"\n",
    "\n",
    "word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Anitya\n",
      "[nltk_data]     Gangurde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.5 Removing Stop Wordsfrom nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Create word tokens\n",
    "tokenized_words = ['i',\n",
    "                    'am',\n",
    "                    'going',\n",
    "                    'to',\n",
    "                    'go',\n",
    "                    'to',\n",
    "                    'the',\n",
    "                    'store',\n",
    "                    'and',\n",
    "                    'park']\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.6 Stemming Words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "porter = PorterStemmer()\n",
    "[porter.stem(word) for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2005-04-03 23:35:00'),\n",
       " Timestamp('2010-05-23 00:01:00'),\n",
       " Timestamp('2009-09-04 21:09:00')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chp 7. Handling Dates and Times\n",
    "#7.1 Converting Strings to Dates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create strings\n",
    "date_strings = np.array(['03-04-2005 11:35 PM',\n",
    "                            '23-05-2010 12:01 AM',\n",
    "                            '04-09-2009 09:09 PM'])\n",
    "\n",
    "#Convert to datetimes\n",
    "[pd.to_datetime(date, format='%d-%m-%Y %I:%M %p') for date in date_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2005-04-03 23:35:00'),\n",
       " Timestamp('2010-05-23 00:01:00'),\n",
       " Timestamp('2009-09-04 21:09:00')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pd.to_datetime(date, format='%d-%m-%Y %I:%M %p', errors=\"coerce\") for date in date_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 06:00:00+0100', tz='Europe/London')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.2 Handling Time Zones\n",
    "import pandas as pd\n",
    "\n",
    "pd.Timestamp('2017-05-01 06:00:00', tz = 'Europe/London')\n",
    "#We can add a time zone to a previously created datetime using tz_localize:\n",
    "date = pd.Timestamp('2017-05-01 06:00:00')\n",
    "date_in_london = date.tz_localize('Europe/London')   \n",
    "date_in_london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-01 05:00:00+0000', tz='Africa/Abidjan')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also convert to a different time zone:\n",
    "date_in_london.tz_convert('Africa/Abidjan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2002-02-28 00:00:00+00:00\n",
       "1   2002-03-31 00:00:00+00:00\n",
       "2   2002-04-30 00:00:00+00:00\n",
       "dtype: datetime64[ns, Africa/Abidjan]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.Series(pd.date_range('2/2/2002', periods=3, freq='M'))\n",
    "dates.dt.tz_localize('Africa/Abidjan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Africa/Abidjan', 'Africa/Accra']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytz import all_timezones\n",
    "all_timezones[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2002-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2002-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2002-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date\n",
       "8762 2002-01-01 02:00:00\n",
       "8763 2002-01-01 03:00:00\n",
       "8764 2002-01-01 04:00:00"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.3 Selecting Dates and Times\n",
    "#Use two boolean conditions as the start and end dates:\n",
    "import pandas as pd\n",
    "# Create data frame\n",
    "dataframe = pd.DataFrame()\n",
    "# Create datetimes\n",
    "dataframe['date'] = pd.date_range('1/1/2001', periods=100000, freq='H')\n",
    "# Select observations between two datetimes\n",
    "dataframe[(dataframe['date'] > '2002-1-1 01:00:00') &\n",
    "            (dataframe['date'] <= '2002-1-1 04:00:00')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-07</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-14</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-21</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year  month  day  hour  minute\n",
       "0 2001-01-07  2001      1    7     0       0\n",
       "1 2001-01-14  2001      1   14     0       0\n",
       "2 2001-01-21  2001      1   21     0       0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.4 Breaking Up Date Data into Multiple Features\n",
    "#Use pandas Series.dts time properties:\n",
    "import pandas as pd\n",
    "# Create data frame\n",
    "dataframe = pd.DataFrame()\n",
    "# Create five dates\n",
    "dataframe['date'] = pd.date_range('1/1/2001', periods=150, freq='W')\n",
    "# Create features for year, month, day, hour, and minute\n",
    "dataframe['year'] = dataframe['date'].dt.year\n",
    "dataframe['month'] = dataframe['date'].dt.month\n",
    "dataframe['day'] = dataframe['date'].dt.day\n",
    "dataframe['hour'] = dataframe['date'].dt.hour\n",
    "dataframe['minute'] = dataframe['date'].dt.minute\n",
    "# Show three rows\n",
    "dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0 days\n",
       "1   2 days\n",
       "dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.5 Calculating the Difference Between Dates\n",
    "#Subtract the two date features using pandas:\n",
    "import pandas as pd\n",
    "# Create data frame\n",
    "dataframe = pd.DataFrame()\n",
    "# Create two datetime features\n",
    "dataframe['Arrived'] = [pd.Timestamp('01-01-2017'), pd.Timestamp('01-04-2017')]\n",
    "dataframe['Left'] = [pd.Timestamp('01-01-2017'), pd.Timestamp('01-06-2017')]\n",
    "# Calculate duration between features\n",
    "dataframe['Left'] - dataframe['Arrived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate duration between features\n",
    "pd.Series(delta.days for delta in (dataframe['Left'] - dataframe['Arrived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    6\n",
       "2    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.6 Encoding Days of the Week\n",
    "#Use pandas Series.dt property weekday_name:\n",
    "import pandas as pd\n",
    "# Create dates\n",
    "dates = pd.Series(pd.date_range(\"2/2/2002\", periods=3, freq=\"M\"))\n",
    "# Show days of the week\n",
    "dates.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>stock_price</th>\n",
       "      <th>previous_days_stock_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dates  stock_price  previous_days_stock_price\n",
       "0 2001-01-01          1.1                        NaN\n",
       "1 2001-01-02          2.2                        1.1\n",
       "2 2001-01-03          3.3                        2.2\n",
       "3 2001-01-04          4.4                        3.3\n",
       "4 2001-01-05          5.5                        4.4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.7 Creating a Lagged Feature\n",
    "#Use pandas shift\n",
    "import pandas as pd\n",
    "# Create data frame\n",
    "dataframe = pd.DataFrame()\n",
    "# Create data\n",
    "dataframe[\"dates\"] = pd.date_range(\"1/1/2001\", periods=5, freq=\"D\")\n",
    "dataframe[\"stock_price\"] = [1.1,2.2,3.3,4.4,5.5]\n",
    "# Lagged values by one row\n",
    "dataframe[\"previous_days_stock_price\"] = dataframe[\"stock_price\"].shift(1)\n",
    "# Show data frame\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Stock_Price\n",
       "2010-01-31          NaN\n",
       "2010-02-28          1.5\n",
       "2010-03-31          2.5\n",
       "2010-04-30          3.5\n",
       "2010-05-31          4.5"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.8 Using Rolling Time Windows\n",
    "import pandas as pd\n",
    "# Create datetimes\n",
    "time_index = pd.date_range(\"01/01/2010\", periods=5, freq=\"M\")\n",
    "# Create data frame, set index\n",
    "dataframe = pd.DataFrame(index=time_index)\n",
    "# Create feature\n",
    "dataframe[\"Stock_Price\"] = [1,2,3,4,5]\n",
    "# Calculate rolling mean\n",
    "dataframe.rolling(window=2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    3.0\n",
       "2010-04-30    4.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.9 Handling Missing Data in Time Series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Create date\n",
    "time_index = pd.date_range(\"01/01/2010\", periods=5, freq=\"M\")\n",
    "dataframe = pd.DataFrame(index=time_index)\n",
    "# Create feature with a gap of missing values\n",
    "dataframe[\"Sales\"] = [1.0,2.0,np.nan,np.nan,5.0]\n",
    "# Interpolate missing values\n",
    "dataframe.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    2.0\n",
       "2010-04-30    2.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    5.0\n",
       "2010-04-30    5.0\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3.059808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>4.038069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sales\n",
       "2010-01-31  1.000000\n",
       "2010-02-28  2.000000\n",
       "2010-03-31  3.059808\n",
       "2010-04-30  4.038069\n",
       "2010-05-31  5.000000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolate missing values\n",
    "dataframe.interpolate(method=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-28</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-31</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales\n",
       "2010-01-31    1.0\n",
       "2010-02-28    2.0\n",
       "2010-03-31    3.0\n",
       "2010-04-30    NaN\n",
       "2010-05-31    5.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolate missing values\n",
    "dataframe.interpolate(limit=1, limit_direction=\"forward\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 54\n"
     ]
    }
   ],
   "source": [
    "#Chp 9. Dimensionality Reduction Using Feature Extraction\n",
    "#9.1 Reducing Features Using Principal Components \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "features = StandardScaler().fit_transform(digits.data)\n",
    "\n",
    "pca = PCA(n_components=0.99, whiten = True)\n",
    "\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 2\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "#9.2 Reducing Features When Data Is Linearly Inseparable\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "features, _ = make_circles(n_samples= 1000, random_state = 1, noise= 0.1, factor= 0.1)\n",
    "\n",
    "kpca = KernelPCA(kernel=\"rbf\", gamma=15, n_components=1)\n",
    "features_kpca=kpca.fit_transform(features)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kpca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.3 Reducing Features by Maximizing Class Separability\n",
    "from sklearn import datasets \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "features_lda = lda.fit(features, target).transform(features)\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_lda.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 10\n"
     ]
    }
   ],
   "source": [
    "#9.4 Reducing Features Using Matrix Factorization\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "features = digits.data\n",
    "nmf = NMF(n_components = 10, random_state=1)\n",
    "features_nmf = nmf.fit_transform(features)\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_nmf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 10\n"
     ]
    }
   ],
   "source": [
    "#9.5 Reducing Features on Sparse Data\n",
    "#Truncated Singular Value Decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "features = StandardScaler().fit_transform(digits.data)\n",
    "features_sparse = csr_matrix(features)\n",
    "tsvd = TruncatedSVD(n_components = 10)\n",
    "features_sparse_tsvd = tsvd.fit(features_sparse).transform(features_sparse)\n",
    "print(\"Original number of features:\", features_sparse.shape[1])\n",
    "print(\"Reduced number of features:\", features_sparse_tsvd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.1 Thresholding Numerical Feature Variance\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "iris = datasets.load_iris()\n",
    "features =iris.data\n",
    "target = iris.target\n",
    "thresholder = VarianceThreshold(threshold=.5)\n",
    "features_high_variance = thresholder.fit_transform(features)\n",
    "features_high_variance[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if the features have been standardized (to mean zero and unit variance), then\n",
    "#for obvious reasons variance thresholding will not work correctly\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize feature matrix\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "# Caculate variance of each feature\n",
    "selector = VarianceThreshold()\n",
    "selector.fit(features_std).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.2 Thresholding Binary Feature Variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# Create feature matrix with:\n",
    "# Feature 0: 80% class 0\n",
    "# Feature 1: 80% class 1\n",
    "# Feature 2: 60% class 0, 40% class 1\n",
    "\n",
    "features = [[0, 1, 0],\n",
    "            [0, 1, 1],\n",
    "            [0, 1, 0],\n",
    "            [0, 1, 1],\n",
    "            [1, 0, 0]]\n",
    "thresholder = VarianceThreshold(threshold=(.75 * (1-.75)))\n",
    "thresholder.fit_transform(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  2\n",
       "0  1  1\n",
       "1  2  0\n",
       "2  3  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.3 Handling Highly Correlated Features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features = np.array([[1, 1, 1],\n",
    "                    [2, 2, 0],\n",
    "                    [3, 3, 1],\n",
    "                    [4, 4, 0],\n",
    "                    [5, 5, 1],\n",
    "                    [6, 6, 0],\n",
    "                    [7, 7, 1],\n",
    "                    [8, 7, 0],\n",
    "                    [9, 7, 1]])\n",
    "\n",
    "df = pd.DataFrame(features)\n",
    "corr_matrix = df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),\n",
    "k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column]> 0.95)]\n",
    "df.drop(df.columns[to_drop], axis = 1).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.976103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034503</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.976103  0.000000\n",
       "1  0.976103  1.000000 -0.034503\n",
       "2  0.000000 -0.034503  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "#10.4 Removing Irrelevant Features for Classification\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "features = features.astype(int)\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "# Select top 75% of features with highest F-values\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "# Show results\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00850799,  0.7031277 ],\n",
       "       [-1.07500204,  2.56148527],\n",
       "       [ 1.37940721, -1.77039484],\n",
       "       ...,\n",
       "       [-0.80331656, -1.60648007],\n",
       "       [ 0.39508844, -1.34564911],\n",
       "       [-0.55383035,  0.82880112]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.5 Recursively Eliminating Features\n",
    "import warnings \n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                   n_features =100, \n",
    "                                   n_informative = 2,\n",
    "                                   random_state=1)\n",
    "ols = linear_model.LinearRegression()\n",
    "\n",
    "rfecv = RFECV(estimator=ols, step = 1, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71, 47, 66, 26, 14,  1, 18,  3, 45, 72, 74, 29,  5, 10, 37, 97, 16,\n",
       "       83, 73, 11, 99,  7, 57, 63, 89, 49, 96, 43, 55, 46,  9, 75, 30, 94,\n",
       "       70, 23, 44, 68, 39,  1, 80, 95, 60, 64, 61, 58, 42, 91, 77, 51, 34,\n",
       "       62, 69, 90, 53, 38, 88, 93, 36, 20, 85, 21, 15, 79, 52, 54, 92, 84,\n",
       "       76, 98,  4, 82, 41,  2, 65, 81, 48, 40, 13, 56,  8, 32, 25, 19,  6,\n",
       "       35, 31, 78, 59, 12, 33, 17, 28, 27, 50, 22, 67, 24, 86, 87])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\Projects\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chp 11. Model Evaluation\n",
    "#11.1 Cross-Validating Models\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "features = digits.data\n",
    "\n",
    "target = digits.target\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state =1)\n",
    "\n",
    "cv_results = cross_val_score(pipeline, \n",
    "                             features, \n",
    "                             target, \n",
    "                             cv = kf, \n",
    "                             scoring=\"accuracy\", \n",
    "                             n_jobs = -1)\n",
    "\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.1, random_state =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit standardizer to training sets\n",
    "standardizer.fit(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11.2 Creating a Baseline Regression Model\n",
    "#You want a simple baseline regression model to compare against your model.\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "features, target = boston.data, boston.target\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "dummy = DummyRegressor(strategy ='mean')\n",
    "\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "dummy.score(features_test, target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202129"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11.3 Creating a Baseline Classification Model\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "dummy = DummyClassifier(strategy = 'uniform', random_state=1)\n",
    "\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classfier = RandomForestClassifier()\n",
    "\n",
    "classfier.fit(features_train, target_train)\n",
    "\n",
    "classfier.score(features_test, target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9555, 0.95  , 0.9585, 0.9555, 0.956 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11.4 Evaluating Binary Classifier Predictions\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 10000,\n",
    "                           n_features = 3,\n",
    "                           n_informative = 3,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 2,\n",
    "                           random_state = 1)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "cross_val_score(logit, X, y, scoring = \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95963673, 0.94820717, 0.9635996 , 0.96149949, 0.96060606])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, X, y, scoring = \"precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.951, 0.952, 0.953, 0.949, 0.951])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, X, y, scoring = \"recall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95529884, 0.9500998 , 0.95827049, 0.95520886, 0.95577889])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, X, y, scoring = \"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#11.5 Evaluating Binary Classifier Thresholds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=10,\n",
    "                                       n_classes=2,\n",
    "                                       n_informative=3,\n",
    "                                       random_state=3)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(features_train, target_train)\n",
    "\n",
    "target_probabilities = logit.predict_proba(features_test)[:,1]\n",
    "\n",
    "false_pos_rate, true_pos_rate, threshold = roc_curve(target_test, target_probabilities)\n",
    "\n",
    "plt.title(\"ROC\")\n",
    "plt.plot(false_pos_rate, true_pos_rate)\n",
    "plt.plot([0,1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9073389355742297"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
